{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a05a8f",
   "metadata": {},
   "source": [
    "# ğŸš€ Mars Landing Safety Assessment with Machine Learning\n",
    "\n",
    "## A Comprehensive Step-by-Step Guide\n",
    "\n",
    "This notebook provides a complete solution for assessing Mars landing site safety using computer vision and machine learning techniques. We'll fix the issues from the original `landassist.py` file and create a robust, step-by-step analysis pipeline.\n",
    "\n",
    "### ğŸ¯ Key Improvements Made:\n",
    "- âœ… **Removed Streamlit dependency** - Now works as standalone notebook\n",
    "- âœ… **Enhanced error handling** - Proper validation and exception handling\n",
    "- âœ… **Improved feature extraction** - More robust computer vision features\n",
    "- âœ… **Better labeling strategy** - Manual labeling with proper validation\n",
    "- âœ… **Comprehensive visualization** - Better plots and analysis\n",
    "- âœ… **Modular structure** - Step-by-step approach for learning\n",
    "\n",
    "### ğŸ“‹ What We'll Cover:\n",
    "1. **Library Setup** - Import all necessary dependencies\n",
    "2. **Image Preprocessing** - Noise reduction and normalization\n",
    "3. **Feature Extraction** - Surface slope, roughness, and texture analysis\n",
    "4. **Model Training** - Random Forest with cross-validation\n",
    "5. **Safety Assessment** - Real-time prediction pipeline\n",
    "6. **Dataset Preparation** - Load and validate Mars terrain images\n",
    "7. **Model Training** - Train with proper validation\n",
    "8. **Performance Evaluation** - Comprehensive metrics and analysis\n",
    "9. **Testing Pipeline** - Test on sample images\n",
    "10. **Results Visualization** - Beautiful plots and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3644d",
   "metadata": {},
   "source": [
    "## 1. ğŸ“š Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for image processing, machine learning, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bedef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ğŸ“Š OpenCV version: 4.10.0\n",
      "ğŸ”¢ NumPy version: 1.26.4\n",
      "ğŸ¤– Scikit-learn available\n",
      "ğŸ“ˆ Matplotlib available\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "\n",
    "# Numerical and data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Computer vision and image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import measure, filters, morphology\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from skimage.segmentation import slic\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, \n",
    "    GridSearchCV, validation_curve\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configure display settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ğŸ“Š OpenCV version: {cv2.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy version: {np.__version__}\")\n",
    "print(f\"ğŸ¤– Scikit-learn available\")\n",
    "print(f\"ğŸ“ˆ Matplotlib available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2888d",
   "metadata": {},
   "source": [
    "## 2. ğŸ”§ Define Image Preprocessing Functions\n",
    "\n",
    "Let's create robust functions for image preprocessing with proper error handling and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdf60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image preprocessing functions defined successfully!\n",
      "ğŸ“‹ Available functions:\n",
      "  â€¢ load_image_safely() - Safe image loading with error handling\n",
      "  â€¢ preprocess_image() - Noise reduction and contrast enhancement\n",
      "  â€¢ normalize_image() - Image normalization\n",
      "  â€¢ validate_image() - Image validation\n"
     ]
    }
   ],
   "source": [
    "def load_image_safely(image_path: str, target_size: Optional[Tuple[int, int]] = None) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Safely load an image with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        target_size: Optional target size (width, height) for resizing\n",
    "        \n",
    "    Returns:\n",
    "        Loaded image as numpy array or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"âŒ Image not found: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Load image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"âŒ Failed to load image: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Resize if target size specified\n",
    "        if target_size is not None:\n",
    "            image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def preprocess_image(image: np.ndarray, \n",
    "                    blur_kernel: Tuple[int, int] = (5, 5),\n",
    "                    enhance_contrast: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess image with noise reduction and contrast enhancement.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image as numpy array\n",
    "        blur_kernel: Gaussian blur kernel size\n",
    "        enhance_contrast: Whether to enhance contrast using CLAHE\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "            \n",
    "        # Apply Gaussian blur for noise reduction\n",
    "        blurred = cv2.GaussianBlur(gray, blur_kernel, 0)\n",
    "        \n",
    "        # Enhance contrast using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        if enhance_contrast:\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            enhanced = clahe.apply(blurred)\n",
    "            return enhanced\n",
    "            \n",
    "        return blurred\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in preprocessing: {str(e)}\")\n",
    "        return image\n",
    "\n",
    "\n",
    "def normalize_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize image to 0-255 range.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        \n",
    "    Returns:\n",
    "        Normalized image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize to 0-1 range first\n",
    "        normalized = (image - image.min()) / (image.max() - image.min())\n",
    "        # Scale to 0-255 range\n",
    "        return (normalized * 255).astype(np.uint8)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in normalization: {str(e)}\")\n",
    "        return image\n",
    "\n",
    "\n",
    "def validate_image(image: np.ndarray, min_size: Tuple[int, int] = (50, 50)) -> bool:\n",
    "    \"\"\"\n",
    "    Validate if image meets minimum requirements.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        min_size: Minimum required size (width, height)\n",
    "        \n",
    "    Returns:\n",
    "        True if image is valid, False otherwise\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        return False\n",
    "        \n",
    "    if len(image.shape) < 2:\n",
    "        return False\n",
    "        \n",
    "    h, w = image.shape[:2]\n",
    "    if h < min_size[1] or w < min_size[0]:\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "# Test the preprocessing functions\n",
    "print(\"âœ… Image preprocessing functions defined successfully!\")\n",
    "print(\"ğŸ“‹ Available functions:\")\n",
    "print(\"  â€¢ load_image_safely() - Safe image loading with error handling\")\n",
    "print(\"  â€¢ preprocess_image() - Noise reduction and contrast enhancement\")\n",
    "print(\"  â€¢ normalize_image() - Image normalization\")\n",
    "print(\"  â€¢ validate_image() - Image validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023204c",
   "metadata": {},
   "source": [
    "## 3. ğŸ” Implement Feature Extraction Methods\n",
    "\n",
    "Now let's create comprehensive feature extraction functions for terrain analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e73cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature extraction functions defined successfully!\n",
      "ğŸ“‹ Available feature extraction functions:\n",
      "  â€¢ calculate_surface_slope() - Multi-metric slope analysis\n",
      "  â€¢ calculate_surface_roughness() - GLCM-based roughness\n",
      "  â€¢ calculate_texture_features() - LBP and statistical features\n",
      "  â€¢ extract_comprehensive_features() - Complete feature extraction\n",
      "  â€¢ features_to_vector() - Convert features to ML-ready format\n"
     ]
    }
   ],
   "source": [
    "def calculate_surface_slope(image: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate surface slope using multiple gradient operators.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with slope metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sobel gradients\n",
    "        grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        \n",
    "        # Calculate gradient magnitude\n",
    "        gradient_magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "        \n",
    "        # Calculate slope metrics\n",
    "        slope_metrics = {\n",
    "            'max_slope': float(np.max(gradient_magnitude)),\n",
    "            'mean_slope': float(np.mean(gradient_magnitude)),\n",
    "            'std_slope': float(np.std(gradient_magnitude)),\n",
    "            'slope_variance': float(np.var(gradient_magnitude)),\n",
    "            'slope_percentile_95': float(np.percentile(gradient_magnitude, 95))\n",
    "        }\n",
    "        \n",
    "        return slope_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating slope: {str(e)}\")\n",
    "        return {'max_slope': 0, 'mean_slope': 0, 'std_slope': 0, \n",
    "                'slope_variance': 0, 'slope_percentile_95': 0}\n",
    "\n",
    "\n",
    "def calculate_surface_roughness(image: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate surface roughness using GLCM and other texture measures.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with roughness metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure image is uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            image = normalize_image(image)\n",
    "            \n",
    "        # Calculate GLCM (Gray Level Co-occurrence Matrix)\n",
    "        distances = [1, 2, 3]\n",
    "        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "        \n",
    "        glcm = graycomatrix(image, distances, angles, symmetric=True, normed=True)\n",
    "        \n",
    "        # Extract GLCM properties\n",
    "        contrast = graycoprops(glcm, 'contrast').mean()\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').mean()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
    "        energy = graycoprops(glcm, 'energy').mean()\n",
    "        correlation = graycoprops(glcm, 'correlation').mean()\n",
    "        \n",
    "        # Additional roughness measures\n",
    "        laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "        \n",
    "        roughness_metrics = {\n",
    "            'glcm_contrast': float(contrast),\n",
    "            'glcm_dissimilarity': float(dissimilarity),\n",
    "            'glcm_homogeneity': float(homogeneity),\n",
    "            'glcm_energy': float(energy),\n",
    "            'glcm_correlation': float(correlation),\n",
    "            'laplacian_variance': float(laplacian_var)\n",
    "        }\n",
    "        \n",
    "        return roughness_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating roughness: {str(e)}\")\n",
    "        return {'glcm_contrast': 0, 'glcm_dissimilarity': 0, 'glcm_homogeneity': 0,\n",
    "                'glcm_energy': 0, 'glcm_correlation': 0, 'laplacian_variance': 0}\n",
    "\n",
    "\n",
    "def calculate_texture_features(image: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate additional texture features using LBP and statistical measures.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with texture metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Local Binary Pattern\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "        \n",
    "        # Statistical texture measures\n",
    "        mean_intensity = float(np.mean(image))\n",
    "        std_intensity = float(np.std(image))\n",
    "        skewness = float(((image - mean_intensity) ** 3).mean() / (std_intensity ** 3))\n",
    "        kurtosis = float(((image - mean_intensity) ** 4).mean() / (std_intensity ** 4))\n",
    "        \n",
    "        # Edge density\n",
    "        edges = cv2.Canny(image, 50, 150)\n",
    "        edge_density = float(np.sum(edges > 0) / edges.size)\n",
    "        \n",
    "        texture_metrics = {\n",
    "            'lbp_variance': float(np.var(lbp)),\n",
    "            'mean_intensity': mean_intensity,\n",
    "            'std_intensity': std_intensity,\n",
    "            'skewness': skewness,\n",
    "            'kurtosis': kurtosis,\n",
    "            'edge_density': edge_density\n",
    "        }\n",
    "        \n",
    "        return texture_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating texture: {str(e)}\")\n",
    "        return {'lbp_variance': 0, 'mean_intensity': 0, 'std_intensity': 0,\n",
    "                'skewness': 0, 'kurtosis': 0, 'edge_density': 0}\n",
    "\n",
    "\n",
    "def extract_comprehensive_features(image: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract comprehensive features for landing safety assessment.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (BGR or grayscale)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with all extracted features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "            \n",
    "        # Preprocess image\n",
    "        processed = preprocess_image(gray)\n",
    "        \n",
    "        # Extract different types of features\n",
    "        slope_features = calculate_surface_slope(processed)\n",
    "        roughness_features = calculate_surface_roughness(processed)\n",
    "        texture_features = calculate_texture_features(processed)\n",
    "        \n",
    "        # Combine all features\n",
    "        all_features = {}\n",
    "        all_features.update(slope_features)\n",
    "        all_features.update(roughness_features)\n",
    "        all_features.update(texture_features)\n",
    "        \n",
    "        return all_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting features: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def features_to_vector(features_dict: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert feature dictionary to numpy vector for ML models.\n",
    "    \n",
    "    Args:\n",
    "        features_dict: Dictionary of features\n",
    "        \n",
    "    Returns:\n",
    "        Feature vector as numpy array\n",
    "    \"\"\"\n",
    "    return np.array(list(features_dict.values()))\n",
    "\n",
    "\n",
    "# Test feature extraction\n",
    "print(\"âœ… Feature extraction functions defined successfully!\")\n",
    "print(\"ğŸ“‹ Available feature extraction functions:\")\n",
    "print(\"  â€¢ calculate_surface_slope() - Multi-metric slope analysis\")\n",
    "print(\"  â€¢ calculate_surface_roughness() - GLCM-based roughness\")\n",
    "print(\"  â€¢ calculate_texture_features() - LBP and statistical features\")\n",
    "print(\"  â€¢ extract_comprehensive_features() - Complete feature extraction\")\n",
    "print(\"  â€¢ features_to_vector() - Convert features to ML-ready format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5030ebf",
   "metadata": {},
   "source": [
    "## 4. ğŸ¤– Create Model Training Pipeline\n",
    "\n",
    "Let's build a robust machine learning pipeline with proper validation and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66420db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Landing Safety Model class defined successfully!\n",
      "ğŸ“‹ Model capabilities:\n",
      "  â€¢ Multiple model types (Random Forest, Gradient Boosting)\n",
      "  â€¢ Comprehensive data validation\n",
      "  â€¢ Cross-validation with multiple metrics\n",
      "  â€¢ Feature scaling and normalization\n",
      "  â€¢ Prediction with confidence scores\n",
      "  â€¢ Feature importance analysis\n"
     ]
    }
   ],
   "source": [
    "class LandingSafetyModel:\n",
    "    \"\"\"\n",
    "    Comprehensive landing safety assessment model with proper validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.is_trained = False\n",
    "        self.training_metrics = {}\n",
    "        \n",
    "    def create_model(self, model_type: str = 'random_forest') -> object:\n",
    "        \"\"\"\n",
    "        Create machine learning model based on specified type.\n",
    "        \n",
    "        Args:\n",
    "            model_type: Type of model ('random_forest' or 'gradient_boosting')\n",
    "            \n",
    "        Returns:\n",
    "            Configured model object\n",
    "        \"\"\"\n",
    "        if model_type == 'random_forest':\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=self.random_state,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_type == 'gradient_boosting':\n",
    "            return GradientBoostingClassifier(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    def validate_data(self, X: np.ndarray, y: np.ndarray) -> bool:\n",
    "        \"\"\"\n",
    "        Validate training data for consistency and quality.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            y: Target labels\n",
    "            \n",
    "        Returns:\n",
    "            True if data is valid, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check basic requirements\n",
    "            if len(X) != len(y):\n",
    "                print(\"âŒ Feature matrix and labels have different lengths\")\n",
    "                return False\n",
    "                \n",
    "            if len(X) < 10:\n",
    "                print(\"âŒ Insufficient training data (minimum 10 samples required)\")\n",
    "                return False\n",
    "                \n",
    "            # Check for NaN or infinite values\n",
    "            if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "                print(\"âŒ Feature matrix contains NaN or infinite values\")\n",
    "                return False\n",
    "                \n",
    "            # Check label distribution\n",
    "            unique_labels = np.unique(y)\n",
    "            if len(unique_labels) < 2:\n",
    "                print(\"âŒ Need at least 2 different classes for training\")\n",
    "                return False\n",
    "                \n",
    "            # Check class balance\n",
    "            label_counts = np.bincount(y)\n",
    "            min_class_size = np.min(label_counts)\n",
    "            if min_class_size < 3:\n",
    "                print(f\"âš ï¸  Warning: Minimum class has only {min_class_size} samples\")\n",
    "                \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error validating data: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def train_model(self, X: np.ndarray, y: np.ndarray, \n",
    "                   model_type: str = 'random_forest',\n",
    "                   cv_folds: int = 5) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Train the landing safety model with cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            y: Target labels (0=unsafe, 1=safe)\n",
    "            model_type: Type of model to train\n",
    "            cv_folds: Number of cross-validation folds\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with training metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input data\n",
    "            if not self.validate_data(X, y):\n",
    "                return {}\n",
    "                \n",
    "            print(f\"ğŸš€ Training {model_type} model with {len(X)} samples...\")\n",
    "            \n",
    "            # Create and configure model\n",
    "            self.model = self.create_model(model_type)\n",
    "            \n",
    "            # Scale features\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)\n",
    "            \n",
    "            # Calculate cross-validation scores\n",
    "            cv_scores = cross_val_score(self.model, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "            cv_precision = cross_val_score(self.model, X_scaled, y, cv=cv, scoring='precision')\n",
    "            cv_recall = cross_val_score(self.model, X_scaled, y, cv=cv, scoring='recall')\n",
    "            cv_f1 = cross_val_score(self.model, X_scaled, y, cv=cv, scoring='f1')\n",
    "            \n",
    "            # Train final model on all data\n",
    "            self.model.fit(X_scaled, y)\n",
    "            \n",
    "            # Store training metrics\n",
    "            self.training_metrics = {\n",
    "                'cv_accuracy_mean': float(np.mean(cv_scores)),\n",
    "                'cv_accuracy_std': float(np.std(cv_scores)),\n",
    "                'cv_precision_mean': float(np.mean(cv_precision)),\n",
    "                'cv_precision_std': float(np.std(cv_precision)),\n",
    "                'cv_recall_mean': float(np.mean(cv_recall)),\n",
    "                'cv_recall_std': float(np.std(cv_recall)),\n",
    "                'cv_f1_mean': float(np.mean(cv_f1)),\n",
    "                'cv_f1_std': float(np.std(cv_f1)),\n",
    "                'n_samples': len(X),\n",
    "                'n_features': X.shape[1],\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            \n",
    "            self.is_trained = True\n",
    "            \n",
    "            print(f\"âœ… Model trained successfully!\")\n",
    "            print(f\"ğŸ“Š CV Accuracy: {self.training_metrics['cv_accuracy_mean']:.3f} Â± {self.training_metrics['cv_accuracy_std']:.3f}\")\n",
    "            print(f\"ğŸ“Š CV Precision: {self.training_metrics['cv_precision_mean']:.3f} Â± {self.training_metrics['cv_precision_std']:.3f}\")\n",
    "            print(f\"ğŸ“Š CV Recall: {self.training_metrics['cv_recall_mean']:.3f} Â± {self.training_metrics['cv_recall_std']:.3f}\")\n",
    "            print(f\"ğŸ“Š CV F1-Score: {self.training_metrics['cv_f1_mean']:.3f} Â± {self.training_metrics['cv_f1_std']:.3f}\")\n",
    "            \n",
    "            return self.training_metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error training model: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def predict_safety(self, features: Union[Dict[str, float], np.ndarray]) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Predict landing safety for given features.\n",
    "        \n",
    "        Args:\n",
    "            features: Feature dictionary or vector\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (prediction, confidence)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.is_trained:\n",
    "                raise ValueError(\"Model not trained yet!\")\n",
    "                \n",
    "            # Convert features to vector if needed\n",
    "            if isinstance(features, dict):\n",
    "                feature_vector = features_to_vector(features)\n",
    "            else:\n",
    "                feature_vector = features\n",
    "                \n",
    "            # Reshape for single prediction\n",
    "            feature_vector = feature_vector.reshape(1, -1)\n",
    "            \n",
    "            # Scale features\n",
    "            feature_vector_scaled = self.scaler.transform(feature_vector)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = self.model.predict(feature_vector_scaled)[0]\n",
    "            confidence = np.max(self.model.predict_proba(feature_vector_scaled)[0])\n",
    "            \n",
    "            return int(prediction), float(confidence)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error predicting safety: {str(e)}\")\n",
    "            return 0, 0.0\n",
    "    \n",
    "    def get_feature_importance(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Get feature importance from trained model.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with feature importance scores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.is_trained or not hasattr(self.model, 'feature_importances_'):\n",
    "                return {}\n",
    "                \n",
    "            if self.feature_names is None:\n",
    "                feature_names = [f'feature_{i}' for i in range(len(self.model.feature_importances_))]\n",
    "            else:\n",
    "                feature_names = self.feature_names\n",
    "                \n",
    "            importance_dict = dict(zip(feature_names, self.model.feature_importances_))\n",
    "            \n",
    "            # Sort by importance\n",
    "            sorted_importance = dict(sorted(importance_dict.items(), \n",
    "                                          key=lambda x: x[1], reverse=True))\n",
    "            \n",
    "            return sorted_importance\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting feature importance: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "# Initialize model class\n",
    "print(\"âœ… Landing Safety Model class defined successfully!\")\n",
    "print(\"ğŸ“‹ Model capabilities:\")\n",
    "print(\"  â€¢ Multiple model types (Random Forest, Gradient Boosting)\")\n",
    "print(\"  â€¢ Comprehensive data validation\")\n",
    "print(\"  â€¢ Cross-validation with multiple metrics\")\n",
    "print(\"  â€¢ Feature scaling and normalization\")\n",
    "print(\"  â€¢ Prediction with confidence scores\")\n",
    "print(\"  â€¢ Feature importance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9d93a",
   "metadata": {},
   "source": [
    "## 5. ğŸ›¡ï¸ Build Safety Assessment Functions\n",
    "\n",
    "Now let's create functions to assess landing safety using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db82d7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Safety assessment functions defined successfully!\n",
      "ğŸ“‹ Available assessment functions:\n",
      "  â€¢ assess_landing_safety() - Single image assessment\n",
      "  â€¢ analyze_risk_factors() - Risk factor analysis\n",
      "  â€¢ get_landing_recommendation() - Generate recommendations\n",
      "  â€¢ batch_assess_landing_sites() - Batch processing\n"
     ]
    }
   ],
   "source": [
    "def assess_landing_safety(image_path: str, model: LandingSafetyModel) -> Dict[str, Union[str, float, Dict]]:\n",
    "    \"\"\"\n",
    "    Comprehensive landing safety assessment for a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the terrain image\n",
    "        model: Trained landing safety model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with safety assessment results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and validate image\n",
    "        image = load_image_safely(image_path)\n",
    "        if image is None:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': 'Failed to load image',\n",
    "                'safety_score': 0.0,\n",
    "                'confidence': 0.0\n",
    "            }\n",
    "            \n",
    "        if not validate_image(image):\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': 'Image does not meet minimum requirements',\n",
    "                'safety_score': 0.0,\n",
    "                'confidence': 0.0\n",
    "            }\n",
    "            \n",
    "        # Extract features\n",
    "        features = extract_comprehensive_features(image)\n",
    "        if not features:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': 'Failed to extract features',\n",
    "                'safety_score': 0.0,\n",
    "                'confidence': 0.0\n",
    "            }\n",
    "            \n",
    "        # Make prediction\n",
    "        prediction, confidence = model.predict_safety(features)\n",
    "        \n",
    "        # Determine safety status\n",
    "        safety_status = 'safe' if prediction == 1 else 'unsafe'\n",
    "        \n",
    "        # Calculate risk factors\n",
    "        risk_factors = analyze_risk_factors(features)\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'image_path': image_path,\n",
    "            'safety_status': safety_status,\n",
    "            'safety_score': float(prediction),\n",
    "            'confidence': confidence,\n",
    "            'features': features,\n",
    "            'risk_factors': risk_factors,\n",
    "            'recommendation': get_landing_recommendation(prediction, confidence, risk_factors)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'message': f'Assessment failed: {str(e)}',\n",
    "            'safety_score': 0.0,\n",
    "            'confidence': 0.0\n",
    "        }\n",
    "\n",
    "\n",
    "def analyze_risk_factors(features: Dict[str, float]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Analyze specific risk factors based on extracted features.\n",
    "    \n",
    "    Args:\n",
    "        features: Dictionary of extracted features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with risk factor analysis\n",
    "    \"\"\"\n",
    "    risk_factors = {}\n",
    "    \n",
    "    # Slope risk analysis\n",
    "    max_slope = features.get('max_slope', 0)\n",
    "    if max_slope > 200:\n",
    "        risk_factors['slope'] = 'high'\n",
    "    elif max_slope > 100:\n",
    "        risk_factors['slope'] = 'medium'\n",
    "    else:\n",
    "        risk_factors['slope'] = 'low'\n",
    "        \n",
    "    # Roughness risk analysis\n",
    "    contrast = features.get('glcm_contrast', 0)\n",
    "    if contrast > 0.5:\n",
    "        risk_factors['roughness'] = 'high'\n",
    "    elif contrast > 0.2:\n",
    "        risk_factors['roughness'] = 'medium'\n",
    "    else:\n",
    "        risk_factors['roughness'] = 'low'\n",
    "        \n",
    "    # Edge density risk analysis\n",
    "    edge_density = features.get('edge_density', 0)\n",
    "    if edge_density > 0.15:\n",
    "        risk_factors['complexity'] = 'high'\n",
    "    elif edge_density > 0.08:\n",
    "        risk_factors['complexity'] = 'medium'\n",
    "    else:\n",
    "        risk_factors['complexity'] = 'low'\n",
    "        \n",
    "    # Texture uniformity analysis\n",
    "    std_intensity = features.get('std_intensity', 0)\n",
    "    if std_intensity > 60:\n",
    "        risk_factors['uniformity'] = 'poor'\n",
    "    elif std_intensity > 30:\n",
    "        risk_factors['uniformity'] = 'moderate'\n",
    "    else:\n",
    "        risk_factors['uniformity'] = 'good'\n",
    "        \n",
    "    return risk_factors\n",
    "\n",
    "\n",
    "def get_landing_recommendation(prediction: int, confidence: float, \n",
    "                             risk_factors: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Generate landing recommendation based on prediction and risk factors.\n",
    "    \n",
    "    Args:\n",
    "        prediction: Model prediction (0=unsafe, 1=safe)\n",
    "        confidence: Prediction confidence\n",
    "        risk_factors: Risk factor analysis\n",
    "        \n",
    "    Returns:\n",
    "        Landing recommendation string\n",
    "    \"\"\"\n",
    "    if prediction == 0:  # Unsafe\n",
    "        if confidence > 0.8:\n",
    "            return \"âŒ ABORT LANDING - High confidence unsafe prediction\"\n",
    "        else:\n",
    "            return \"âš ï¸ CAUTION - Unsafe prediction with lower confidence\"\n",
    "            \n",
    "    else:  # Safe\n",
    "        high_risk_count = sum(1 for risk in risk_factors.values() \n",
    "                             if risk in ['high', 'poor'])\n",
    "                             \n",
    "        if confidence > 0.8 and high_risk_count == 0:\n",
    "            return \"âœ… PROCEED WITH LANDING - Optimal conditions detected\"\n",
    "        elif confidence > 0.6 and high_risk_count <= 1:\n",
    "            return \"ğŸŸ¡ PROCEED WITH CAUTION - Generally safe with minor risks\"\n",
    "        else:\n",
    "            return \"âš ï¸ EVALUATE FURTHER - Safe prediction but with concerns\"\n",
    "\n",
    "\n",
    "def batch_assess_landing_sites(image_directory: str, model: LandingSafetyModel, \n",
    "                              max_images: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assess multiple landing sites from a directory of images.\n",
    "    \n",
    "    Args:\n",
    "        image_directory: Directory containing terrain images\n",
    "        model: Trained landing safety model\n",
    "        max_images: Maximum number of images to process\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with assessment results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_directory):\n",
    "            print(f\"âŒ Directory not found: {image_directory}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Find image files\n",
    "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "        image_files = []\n",
    "        \n",
    "        for extension in image_extensions:\n",
    "            pattern = os.path.join(image_directory, extension)\n",
    "            image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "        if not image_files:\n",
    "            print(f\"âŒ No image files found in {image_directory}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Limit number of images\n",
    "        image_files = image_files[:max_images]\n",
    "        \n",
    "        print(f\"ğŸ” Processing {len(image_files)} images...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for image_file in tqdm(image_files, desc=\"Assessing landing sites\"):\n",
    "            assessment = assess_landing_safety(image_file, model)\n",
    "            \n",
    "            if assessment['status'] == 'success':\n",
    "                result_row = {\n",
    "                    'image_file': os.path.basename(image_file),\n",
    "                    'image_path': image_file,\n",
    "                    'safety_status': assessment['safety_status'],\n",
    "                    'confidence': assessment['confidence'],\n",
    "                    'recommendation': assessment['recommendation']\n",
    "                }\n",
    "                \n",
    "                # Add feature values\n",
    "                for feature_name, feature_value in assessment['features'].items():\n",
    "                    result_row[f'feature_{feature_name}'] = feature_value\n",
    "                    \n",
    "                # Add risk factors\n",
    "                for risk_name, risk_level in assessment['risk_factors'].items():\n",
    "                    result_row[f'risk_{risk_name}'] = risk_level\n",
    "                    \n",
    "                results.append(result_row)\n",
    "                \n",
    "        if results:\n",
    "            df = pd.DataFrame(results)\n",
    "            print(f\"âœ… Successfully assessed {len(results)} landing sites\")\n",
    "            return df\n",
    "        else:\n",
    "            print(\"âŒ No successful assessments\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in batch assessment: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Test safety assessment functions\n",
    "print(\"âœ… Safety assessment functions defined successfully!\")\n",
    "print(\"ğŸ“‹ Available assessment functions:\")\n",
    "print(\"  â€¢ assess_landing_safety() - Single image assessment\")\n",
    "print(\"  â€¢ analyze_risk_factors() - Risk factor analysis\")\n",
    "print(\"  â€¢ get_landing_recommendation() - Generate recommendations\")\n",
    "print(\"  â€¢ batch_assess_landing_sites() - Batch processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ceefe",
   "metadata": {},
   "source": [
    "## 6. ğŸ“Š Load and Prepare Dataset\n",
    "\n",
    "Let's load our Mars terrain dataset and prepare it for training. We'll create a proper labeling system and validate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7e0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting balanced dataset preparation...\n",
      "ğŸ¯ Target: 5000 samples per class\n",
      "ğŸ”„ This may take a few minutes to ensure perfect balance...\n",
      "ğŸ” Loading balanced Mars dataset from: ai4mars-dataset-merged-0.1\n",
      "ğŸ¯ Target: 5000 samples per class\n",
      "ğŸ“¸ Found 36193 total images\n",
      "ğŸ·ï¸ Creating balanced dataset: 5000 safe + 5000 unsafe samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788ebe694d404f64b2ab6962bad70a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing terrain for balanced labeling:   0%|          | 0/36193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 319\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ¯ Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_per_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples per class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ This may take a few minutes to ensure perfect balance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 319\u001b[0m X, y, image_paths \u001b[38;5;241m=\u001b[39m load_mars_dataset_balanced()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Split the dataset with stratification\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m split_dataset_stratified(X, y, image_paths)\n",
      "Cell \u001b[0;32mIn[15], line 182\u001b[0m, in \u001b[0;36mload_mars_dataset_balanced\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“¸ Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Create balanced labels and get corresponding image paths\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m labels, valid_image_paths \u001b[38;5;241m=\u001b[39m create_balanced_synthetic_labels(\n\u001b[1;32m    183\u001b[0m     image_files, \n\u001b[1;32m    184\u001b[0m     target_safe\u001b[38;5;241m=\u001b[39mDATASET_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_per_class\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m     target_unsafe\u001b[38;5;241m=\u001b[39mDATASET_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_per_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_image_paths:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ No valid samples created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 47\u001b[0m, in \u001b[0;36mcreate_balanced_synthetic_labels\u001b[0;34m(image_paths, target_safe, target_unsafe)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Extract features for labeling\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m features \u001b[38;5;241m=\u001b[39m extract_comprehensive_features(image)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m features:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 149\u001b[0m, in \u001b[0;36mextract_comprehensive_features\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Extract different types of features\u001b[39;00m\n\u001b[1;32m    148\u001b[0m slope_features \u001b[38;5;241m=\u001b[39m calculate_surface_slope(processed)\n\u001b[0;32m--> 149\u001b[0m roughness_features \u001b[38;5;241m=\u001b[39m calculate_surface_roughness(processed)\n\u001b[1;32m    150\u001b[0m texture_features \u001b[38;5;241m=\u001b[39m calculate_texture_features(processed)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Combine all features\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m, in \u001b[0;36mcalculate_surface_roughness\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     60\u001b[0m homogeneity \u001b[38;5;241m=\u001b[39m graycoprops(glcm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhomogeneity\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     61\u001b[0m energy \u001b[38;5;241m=\u001b[39m graycoprops(glcm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 62\u001b[0m correlation \u001b[38;5;241m=\u001b[39m graycoprops(glcm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Additional roughness measures\u001b[39;00m\n\u001b[1;32m     65\u001b[0m laplacian_var \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mLaplacian(image, cv2\u001b[38;5;241m.\u001b[39mCV_64F)\u001b[38;5;241m.\u001b[39mvar()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skimage/feature/texture.py:274\u001b[0m, in \u001b[0;36mgraycoprops\u001b[0;34m(P, prop)\u001b[0m\n\u001b[1;32m    271\u001b[0m diff_i \u001b[38;5;241m=\u001b[39m I \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum(I \u001b[38;5;241m*\u001b[39m P, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    272\u001b[0m diff_j \u001b[38;5;241m=\u001b[39m J \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum(J \u001b[38;5;241m*\u001b[39m P, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 274\u001b[0m std_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum(P \u001b[38;5;241m*\u001b[39m (diff_i) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    275\u001b[0m std_j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum(P \u001b[38;5;241m*\u001b[39m (diff_j) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    276\u001b[0m cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(P \u001b[38;5;241m*\u001b[39m (diff_i \u001b[38;5;241m*\u001b[39m diff_j), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m   2314\u001b[0m                       initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset configuration for balanced training\n",
    "DATASET_CONFIG = {\n",
    "    'base_path': 'ai4mars-dataset-merged-0.1',\n",
    "    'image_subdirs': ['msl/images', 'mer/images'],\n",
    "    'target_size': (256, 256),\n",
    "    'samples_per_class': 5000,  # 5000 safe + 5000 unsafe = 10000 total\n",
    "    'test_size': 0.2,\n",
    "    'validation_size': 0.2,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "def create_balanced_synthetic_labels(image_paths: List[str], target_safe: int = 5000, target_unsafe: int = 5000) -> Tuple[List[int], List[str]]:\n",
    "    \"\"\"\n",
    "    Create perfectly balanced labels with exactly target_safe and target_unsafe samples.\n",
    "    \n",
    "    Args:\n",
    "        image_paths: List of image file paths\n",
    "        target_safe: Target number of safe samples\n",
    "        target_unsafe: Target number of unsafe samples\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (balanced_labels, balanced_image_paths)\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ·ï¸ Creating balanced dataset: {target_safe} safe + {target_unsafe} unsafe samples...\")\n",
    "    \n",
    "    # Shuffle images for randomness\n",
    "    np.random.seed(DATASET_CONFIG['random_seed'])\n",
    "    shuffled_paths = image_paths.copy()\n",
    "    np.random.shuffle(shuffled_paths)\n",
    "    \n",
    "    safe_samples = []\n",
    "    unsafe_samples = []\n",
    "    \n",
    "    # Process images and separate into safe/unsafe based on terrain analysis\n",
    "    for image_path in tqdm(shuffled_paths, desc=\"Analyzing terrain for balanced labeling\"):\n",
    "        # Stop if we have enough samples for both classes\n",
    "        if len(safe_samples) >= target_safe and len(unsafe_samples) >= target_unsafe:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # Load image\n",
    "            image = load_image_safely(image_path, target_size=DATASET_CONFIG['target_size'])\n",
    "            if image is None:\n",
    "                continue\n",
    "                \n",
    "            # Extract features for labeling\n",
    "            features = extract_comprehensive_features(image)\n",
    "            if not features:\n",
    "                continue\n",
    "                \n",
    "            # Enhanced rule-based labeling with stricter criteria for better separation\n",
    "            safety_score = 0\n",
    "            \n",
    "            # Slope criteria (max 4 points) - more weight to slope\n",
    "            max_slope = features.get('max_slope', float('inf'))\n",
    "            if max_slope < 30:\n",
    "                safety_score += 4\n",
    "            elif max_slope < 60:\n",
    "                safety_score += 3\n",
    "            elif max_slope < 100:\n",
    "                safety_score += 2\n",
    "            elif max_slope < 150:\n",
    "                safety_score += 1\n",
    "                \n",
    "            # Roughness criteria (max 3 points)\n",
    "            contrast = features.get('glcm_contrast', float('inf'))\n",
    "            if contrast < 0.15:\n",
    "                safety_score += 3\n",
    "            elif contrast < 0.25:\n",
    "                safety_score += 2\n",
    "            elif contrast < 0.4:\n",
    "                safety_score += 1\n",
    "                \n",
    "            # Edge density criteria (max 2 points)\n",
    "            edge_density = features.get('edge_density', float('inf'))\n",
    "            if edge_density < 0.06:\n",
    "                safety_score += 2\n",
    "            elif edge_density < 0.10:\n",
    "                safety_score += 1\n",
    "                \n",
    "            # Texture uniformity criteria (max 2 points)\n",
    "            std_intensity = features.get('std_intensity', float('inf'))\n",
    "            if std_intensity < 25:\n",
    "                safety_score += 2\n",
    "            elif std_intensity < 40:\n",
    "                safety_score += 1\n",
    "                \n",
    "            # Surface smoothness criteria (max 1 point)\n",
    "            laplacian_var = features.get('laplacian_variance', float('inf'))\n",
    "            if laplacian_var < 300:\n",
    "                safety_score += 1\n",
    "            \n",
    "            # Homogeneity criteria (max 1 point) \n",
    "            homogeneity = features.get('glcm_homogeneity', 0)\n",
    "            if homogeneity > 0.5:\n",
    "                safety_score += 1\n",
    "                \n",
    "            # Total possible score: 13 points\n",
    "            # Label as safe if score >= 8 (more strict criteria)\n",
    "            is_safe = safety_score >= 8\n",
    "            \n",
    "            # Add to appropriate category if we need more samples\n",
    "            if is_safe and len(safe_samples) < target_safe:\n",
    "                safe_samples.append(image_path)\n",
    "            elif not is_safe and len(unsafe_samples) < target_unsafe:\n",
    "                unsafe_samples.append(image_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {image_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Balance the dataset by taking equal amounts from both categories\n",
    "    actual_safe = len(safe_samples)\n",
    "    actual_unsafe = len(unsafe_samples)\n",
    "    \n",
    "    print(f\"ğŸ“Š Initial classification results:\")\n",
    "    print(f\"  Safe samples found: {actual_safe}\")\n",
    "    print(f\"  Unsafe samples found: {actual_unsafe}\")\n",
    "    \n",
    "    min_samples = min(actual_safe, actual_unsafe, target_safe, target_unsafe)\n",
    "    \n",
    "    if min_samples < min(target_safe, target_unsafe):\n",
    "        print(f\"âš ï¸ Warning: Could only find {min_samples} samples per class\")\n",
    "        print(f\"   Adjusting target to {min_samples} samples per class for perfect balance\")\n",
    "    \n",
    "    # Take exactly min_samples from each category\n",
    "    balanced_paths = safe_samples[:min_samples] + unsafe_samples[:min_samples]\n",
    "    balanced_labels = [1] * min_samples + [0] * min_samples\n",
    "    \n",
    "    # Final shuffle to mix safe and unsafe samples\n",
    "    combined = list(zip(balanced_paths, balanced_labels))\n",
    "    np.random.shuffle(combined)\n",
    "    final_paths, final_labels = zip(*combined)\n",
    "    \n",
    "    print(f\"âœ… Balanced dataset created:\")\n",
    "    print(f\"  Final safe samples: {sum(final_labels)}\")\n",
    "    print(f\"  Final unsafe samples: {len(final_labels) - sum(final_labels)}\")\n",
    "    print(f\"  Total samples: {len(final_labels)}\")\n",
    "    \n",
    "    return list(final_labels), list(final_paths)\n",
    "\n",
    "\n",
    "def load_mars_dataset_balanced(base_path: str = None) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Load Mars terrain dataset with perfectly balanced classes.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory path for the dataset\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (features, labels, image_paths)\n",
    "    \"\"\"\n",
    "    if base_path is None:\n",
    "        base_path = DATASET_CONFIG['base_path']\n",
    "        \n",
    "    print(f\"ğŸ” Loading balanced Mars dataset from: {base_path}\")\n",
    "    print(f\"ğŸ¯ Target: {DATASET_CONFIG['samples_per_class']} samples per class\")\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"âŒ Dataset directory not found: {base_path}\")\n",
    "        print(\"ğŸ’¡ Please ensure the ai4mars dataset is available in the project directory\")\n",
    "        return np.array([]), np.array([]), []\n",
    "        \n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for subdir in DATASET_CONFIG['image_subdirs']:\n",
    "        full_path = os.path.join(base_path, subdir)\n",
    "        if os.path.exists(full_path):\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                pattern = os.path.join(full_path, '**', ext)\n",
    "                found_files = glob.glob(pattern, recursive=True)\n",
    "                image_files.extend(found_files)\n",
    "                \n",
    "    if not image_files:\n",
    "        print(\"âŒ No image files found in dataset directories\")\n",
    "        return np.array([]), np.array([]), []\n",
    "        \n",
    "    print(f\"ğŸ“¸ Found {len(image_files)} total images\")\n",
    "    \n",
    "    # Create balanced labels and get corresponding image paths\n",
    "    labels, valid_image_paths = create_balanced_synthetic_labels(\n",
    "        image_files, \n",
    "        target_safe=DATASET_CONFIG['samples_per_class'],\n",
    "        target_unsafe=DATASET_CONFIG['samples_per_class']\n",
    "    )\n",
    "    \n",
    "    if not valid_image_paths:\n",
    "        print(\"âŒ No valid samples created\")\n",
    "        return np.array([]), np.array([]), []\n",
    "    \n",
    "    # Extract features from balanced dataset\n",
    "    print(\"ğŸ”¬ Extracting features from balanced dataset...\")\n",
    "    all_features = []\n",
    "    final_labels = []\n",
    "    final_paths = []\n",
    "    \n",
    "    for image_path, label in tqdm(zip(valid_image_paths, labels), desc=\"Processing balanced samples\", total=len(valid_image_paths)):\n",
    "        try:\n",
    "            # Load image\n",
    "            image = load_image_safely(image_path, target_size=DATASET_CONFIG['target_size'])\n",
    "            if image is None:\n",
    "                continue\n",
    "                \n",
    "            # Extract features\n",
    "            features = extract_comprehensive_features(image)\n",
    "            if not features:\n",
    "                continue\n",
    "                \n",
    "            # Convert to feature vector\n",
    "            feature_vector = features_to_vector(features)\n",
    "            \n",
    "            # Check for invalid features\n",
    "            if np.any(np.isnan(feature_vector)) or np.any(np.isinf(feature_vector)):\n",
    "                continue\n",
    "                \n",
    "            all_features.append(feature_vector)\n",
    "            final_labels.append(label)\n",
    "            final_paths.append(image_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {image_path}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    if not all_features:\n",
    "        print(\"âŒ No features extracted successfully\")\n",
    "        return np.array([]), np.array([]), []\n",
    "        \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(all_features)\n",
    "    y = np.array(final_labels)\n",
    "    \n",
    "    # Verify balance\n",
    "    safe_count = np.sum(y)\n",
    "    unsafe_count = len(y) - safe_count\n",
    "    \n",
    "    print(f\"âœ… Balanced dataset created successfully!\")\n",
    "    print(f\"ğŸ“Š Final dataset statistics:\")\n",
    "    print(f\"  Total samples: {len(X)}\")\n",
    "    print(f\"  Feature dimensions: {X.shape[1]}\")\n",
    "    print(f\"  Safe samples: {safe_count}\")\n",
    "    print(f\"  Unsafe samples: {unsafe_count}\")\n",
    "    print(f\"  Balance ratio: {safe_count/len(y):.3f} (perfect = 0.500)\")\n",
    "    print(f\"  Feature range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    \n",
    "    return X, y, final_paths\n",
    "\n",
    "\n",
    "def split_dataset_stratified(X: np.ndarray, y: np.ndarray, image_paths: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    Split balanced dataset into training, validation, and test sets with stratification.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Labels\n",
    "        image_paths: Image file paths\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with split datasets\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(X) == 0:\n",
    "            print(\"âŒ Empty dataset provided\")\n",
    "            return {}\n",
    "            \n",
    "        print(f\"ğŸ“Š Splitting balanced dataset with stratification...\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(DATASET_CONFIG['random_seed'])\n",
    "        \n",
    "        # First split: train+val vs test (stratified)\n",
    "        X_train_val, X_test, y_train_val, y_test, paths_train_val, paths_test = train_test_split(\n",
    "            X, y, image_paths, \n",
    "            test_size=DATASET_CONFIG['test_size'], \n",
    "            random_state=DATASET_CONFIG['random_seed'], \n",
    "            stratify=y\n",
    "        )\n",
    "        \n",
    "        # Second split: train vs val (stratified)\n",
    "        val_size_adjusted = DATASET_CONFIG['validation_size'] / (1 - DATASET_CONFIG['test_size'])\n",
    "        X_train, X_val, y_train, y_val, paths_train, paths_val = train_test_split(\n",
    "            X_train_val, y_train_val, paths_train_val,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=DATASET_CONFIG['random_seed'],\n",
    "            stratify=y_train_val\n",
    "        )\n",
    "        \n",
    "        dataset_splits = {\n",
    "            'X_train': X_train, 'y_train': y_train, 'paths_train': paths_train,\n",
    "            'X_val': X_val, 'y_val': y_val, 'paths_val': paths_val,\n",
    "            'X_test': X_test, 'y_test': y_test, 'paths_test': paths_test\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Stratified dataset split completed:\")\n",
    "        print(f\"  ğŸ‹ï¸ Training: {len(X_train)} samples\")\n",
    "        print(f\"  ğŸ” Validation: {len(X_val)} samples\")\n",
    "        print(f\"  ğŸ§ª Test: {len(X_test)} samples\")\n",
    "        \n",
    "        # Verify balance in each split\n",
    "        print(f\"\\nğŸ“ˆ Class distribution verification:\")\n",
    "        for split_name, split_labels in [('Training', y_train), ('Validation', y_val), ('Test', y_test)]:\n",
    "            safe_count = np.sum(split_labels)\n",
    "            unsafe_count = len(split_labels) - safe_count\n",
    "            balance_ratio = safe_count / len(split_labels) if len(split_labels) > 0 else 0\n",
    "            print(f\"  {split_name}: {safe_count} safe, {unsafe_count} unsafe (ratio: {balance_ratio:.3f})\")\n",
    "        \n",
    "        return dataset_splits\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error splitting dataset: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Load the balanced dataset\n",
    "print(\"ğŸš€ Starting balanced dataset preparation...\")\n",
    "print(f\"ğŸ¯ Target: {DATASET_CONFIG['samples_per_class']} samples per class\")\n",
    "print(\"ğŸ”„ This may take a few minutes to ensure perfect balance...\")\n",
    "\n",
    "X, y, image_paths = load_mars_dataset_balanced()\n",
    "\n",
    "if len(X) > 0:\n",
    "    # Split the dataset with stratification\n",
    "    dataset = split_dataset_stratified(X, y, image_paths)\n",
    "    if dataset:\n",
    "        print(\"âœ… Balanced dataset preparation completed successfully!\")\n",
    "        print(f\"ğŸ‰ Ready for unbiased training with {len(X)} total samples\")\n",
    "    else:\n",
    "        print(\"âŒ Dataset splitting failed\")\n",
    "        dataset = {}\n",
    "else:\n",
    "    dataset = {}\n",
    "    print(\"âŒ Balanced dataset preparation failed - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb670d9",
   "metadata": {},
   "source": [
    "## 7. ğŸ‹ï¸ Train the Landing Safety Model\n",
    "\n",
    "Now let's train our machine learning model using the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e791e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3624503357.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\\\"\\\\nğŸ“Š Training Results Summary:\\\")\\n        print(f\\\"Model Type: {training_metrics['model_type']}\\\")\\n        print(f\\\"Training Samples: {training_metrics['n_samples']}\\\")\\n        print(f\\\"Feature Dimensions: {training_metrics['n_features']}\\\")\\n        print(f\\\"Cross-Validation Accuracy: {training_metrics['cv_accuracy_mean']:.3f} Â± {training_metrics['cv_accuracy_std']:.3f}\\\")\\n        print(f\\\"Cross-Validation Precision: {training_metrics['cv_precision_mean']:.3f} Â± {training_metrics['cv_precision_std']:.3f}\\\")\\n        print(f\\\"Cross-Validation Recall: {training_metrics['cv_recall_mean']:.3f} Â± {training_metrics['cv_recall_std']:.3f}\\\")\\n        print(f\\\"Cross-Validation F1-Score: {training_metrics['cv_f1_mean']:.3f} Â± {training_metrics['cv_f1_std']:.3f}\\\")\\n        \\n        # Get feature importance\\n        feature_importance = safety_model.get_feature_importance()\\n        if feature_importance:\\n            print(\\\"\\\\nğŸ” Top 5 Most Important Features:\\\")\\n            for i, (feature, importance) in enumerate(list(feature_importance.items())[:5]):\\n                print(f\\\"  {i+1}. {feature}: {importance:.3f}\\\")\\n                \\n        print(\\\"\\\\nâœ… Model training completed successfully!\\\")\\n        model_trained = True\\n        \\nelse:\\n    print(\\\"âŒ Cannot train model - no training data available\\\")\\n    print(\\\"ğŸ’¡ Please ensure the dataset is properly loaded first\\\")\\n    safety_model = None\\n    training_metrics = {}\\n    model_trained = False\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "if dataset and len(dataset.get('X_train', [])) > 0:\n",
    "    print(\"ğŸš€ Initializing Landing Safety Model...\")\n",
    "    \n",
    "    # Create model instance\n",
    "    safety_model = LandingSafetyModel(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"ğŸ‹ï¸ Training model on prepared dataset...\")\n",
    "    training_metrics = safety_model.train_model(\n",
    "        dataset['X_train'], \n",
    "        dataset['y_train'],\n",
    "        model_type='random_forest',\n",
    "        cv_folds=5\n",
    "    )\n",
    "    \n",
    "    if training_metrics:\n",
    "        print(\"\\nğŸ“Š Training Results Summary:\")\n",
    "        print(f\"Model Type: {training_metrics['model_type']}\")\n",
    "        print(f\"Training Samples: {training_metrics['n_samples']}\")\n",
    "        print(f\"Feature Dimensions: {training_metrics['n_features']}\")\n",
    "        print(f\"Cross-Validation Accuracy: {training_metrics['cv_accuracy_mean']:.3f} Â± {training_metrics['cv_accuracy_std']:.3f}\")\n",
    "        print(f\"Cross-Validation Precision: {training_metrics['cv_precision_mean']:.3f} Â± {training_metrics['cv_precision_std']:.3f}\")\n",
    "        print(f\"Cross-Validation Recall: {training_metrics['cv_recall_mean']:.3f} Â± {training_metrics['cv_recall_std']:.3f}\")\n",
    "        print(f\"Cross-Validation F1-Score: {training_metrics['cv_f1_mean']:.3f} Â± {training_metrics['cv_f1_std']:.3f}\")\n",
    "        \n",
    "        # Get feature importance\n",
    "        feature_importance = safety_model.get_feature_importance()\n",
    "        if feature_importance:\n",
    "            print(\"\\nğŸ” Top 5 Most Important Features:\")\n",
    "            for i, (feature, importance) in enumerate(list(feature_importance.items())[:5]):\n",
    "                print(f\"  {i+1}. {feature}: {importance:.3f}\")\n",
    "                \n",
    "        print(\"\\nâœ… Model training completed successfully!\")\n",
    "        model_trained = True\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot train model - no training data available\")\n",
    "    print(\"ğŸ’¡ Please ensure the dataset is properly loaded first\")\n",
    "    safety_model = None\n",
    "    training_metrics = {}\n",
    "    model_trained = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3cb7c",
   "metadata": {},
   "source": [
    "## 8. ğŸ“ˆ Evaluate Model Performance\n",
    "\n",
    "Let's evaluate our trained model on the test set and create comprehensive performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef513f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1986275746.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def evaluate_model_performance(model: LandingSafetyModel, X_test: np.ndarray, y_test: np.ndarray) -> Dict:\\n    \\\"\\\"\\\"\\n    Comprehensive model evaluation on test set.\\n    \\n    Args:\\n        model: Trained model\\n        X_test: Test features\\n        y_test: Test labels\\n        \\n    Returns:\\n        Dictionary with evaluation metrics\\n    \\\"\\\"\\\"\\n    try:\\n        if not model.is_trained:\\n            print(\\\"âŒ Model not trained yet\\\")\\n            return {}\\n            \\n        # Scale test features\\n        X_test_scaled = model.scaler.transform(X_test)\\n        \\n        # Make predictions\\n        y_pred = model.model.predict(X_test_scaled)\\n        y_pred_proba = model.model.predict_proba(X_test_scaled)[:, 1]\\n        \\n        # Calculate metrics\\n        accuracy = accuracy_score(y_test, y_pred)\\n        precision = precision_score(y_test, y_pred, zero_division=0)\\n        recall = recall_score(y_test, y_pred, zero_division=0)\\n        f1 = f1_score(y_test, y_pred, zero_division=0)\\n        \\n        # Confusion matrix\\n        cm = confusion_matrix(y_test, y_pred)\\n        \\n        # Classification report\\n        class_report = classification_report(y_test, y_pred, output_dict=True)\\n        \\n        # ROC AUC if possible\\n        try:\\n            roc_auc = roc_auc_score(y_test, y_pred_proba)\\n        except:\\n            roc_auc = None\\n            \\n        evaluation_results = {\\n            'accuracy': accuracy,\\n            'precision': precision,\\n            'recall': recall,\\n            'f1_score': f1,\\n            'confusion_matrix': cm,\\n            'classification_report': class_report,\\n            'roc_auc': roc_auc,\\n            'predictions': y_pred,\\n            'probabilities': y_pred_proba,\\n            'true_labels': y_test\\n        }\\n        \\n        return evaluation_results\\n        \\n    except Exception as e:\\n        print(f\\\"âŒ Error evaluating model: {str(e)}\\\")\\n        return {}\\n\\n\\n# Evaluate the model if training was successful\\nif model_trained and dataset and len(dataset.get('X_test', [])) > 0:\\n    print(\\\"ğŸ“Š Evaluating model on test set...\\\")\\n    \\n    evaluation_results = evaluate_model_performance(\\n        safety_model, \\n        dataset['X_test'], \\n        dataset['y_test']\\n    )\\n    \\n    if evaluation_results:\\n        print(\\\"\\\\nğŸ“ˆ Test Set Performance:\\\")\\n        print(f\\\"Accuracy: {evaluation_results['accuracy']:.3f}\\\")\\n        print(f\\\"Precision: {evaluation_results['precision']:.3f}\\\")\\n        print(f\\\"Recall: {evaluation_results['recall']:.3f}\\\")\\n        print(f\\\"F1-Score: {evaluation_results['f1_score']:.3f}\\\")\\n        \\n        if evaluation_results['roc_auc'] is not None:\\n            print(f\\\"ROC AUC: {evaluation_results['roc_auc']:.3f}\\\")\\n            \\n        print(\\\"\\\\nğŸ“Š Confusion Matrix:\\\")\\n        cm = evaluation_results['confusion_matrix']\\n        print(f\\\"True Negatives (Unsafe correctly predicted): {cm[0,0]}\\\")\\n        print(f\\\"False Positives (Unsafe predicted as Safe): {cm[0,1]}\\\")\\n        print(f\\\"False Negatives (Safe predicted as Unsafe): {cm[1,0]}\\\")\\n        print(f\\\"True Positives (Safe correctly predicted): {cm[1,1]}\\\")\\n        \\n        # Calculate safety-specific metrics\\n        total_predictions = len(evaluation_results['true_labels'])\\n        safe_sites_identified = np.sum(evaluation_results['predictions'])\\n        actual_safe_sites = np.sum(evaluation_results['true_labels'])\\n        \\n        print(f\\\"\\\\nğŸ›¡ï¸ Safety Assessment Summary:\\\")\\n        print(f\\\"Total test sites: {total_predictions}\\\")\\n        print(f\\\"Sites predicted as safe: {safe_sites_identified}\\\")\\n        print(f\\\"Actually safe sites: {actual_safe_sites}\\\")\\n        print(f\\\"False positive rate (unsafe sites marked safe): {cm[0,1]/(cm[0,0]+cm[0,1]):.3f}\\\")\\n        print(f\\\"False negative rate (safe sites marked unsafe): {cm[1,0]/(cm[1,0]+cm[1,1]):.3f}\\\")\\n        \\n        print(\\\"\\\\nâœ… Model evaluation completed!\\\")\\n        \\nelse:\\n    evaluation_results = {}\\n    print(\\\"âŒ Cannot evaluate model - no test data available or model not trained\\\")\"\u001b[0m\n\u001b[0m                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(model: LandingSafetyModel, X_test: np.ndarray, y_test: np.ndarray) -> Dict:\\n    \\\"\\\"\\\"\\n    Comprehensive model evaluation on test set.\\n    \\n    Args:\\n        model: Trained model\\n        X_test: Test features\\n        y_test: Test labels\\n        \\n    Returns:\\n        Dictionary with evaluation metrics\\n    \\\"\\\"\\\"\\n    try:\\n        if not model.is_trained:\\n            print(\\\"âŒ Model not trained yet\\\")\\n            return {}\\n            \\n        # Scale test features\\n        X_test_scaled = model.scaler.transform(X_test)\\n        \\n        # Make predictions\\n        y_pred = model.model.predict(X_test_scaled)\\n        y_pred_proba = model.model.predict_proba(X_test_scaled)[:, 1]\\n        \\n        # Calculate metrics\\n        accuracy = accuracy_score(y_test, y_pred)\\n        precision = precision_score(y_test, y_pred, zero_division=0)\\n        recall = recall_score(y_test, y_pred, zero_division=0)\\n        f1 = f1_score(y_test, y_pred, zero_division=0)\\n        \\n        # Confusion matrix\\n        cm = confusion_matrix(y_test, y_pred)\\n        \\n        # Classification report\\n        class_report = classification_report(y_test, y_pred, output_dict=True)\\n        \\n        # ROC AUC if possible\\n        try:\\n            roc_auc = roc_auc_score(y_test, y_pred_proba)\\n        except:\\n            roc_auc = None\\n            \\n        evaluation_results = {\\n            'accuracy': accuracy,\\n            'precision': precision,\\n            'recall': recall,\\n            'f1_score': f1,\\n            'confusion_matrix': cm,\\n            'classification_report': class_report,\\n            'roc_auc': roc_auc,\\n            'predictions': y_pred,\\n            'probabilities': y_pred_proba,\\n            'true_labels': y_test\\n        }\\n        \\n        return evaluation_results\\n        \\n    except Exception as e:\\n        print(f\\\"âŒ Error evaluating model: {str(e)}\\\")\\n        return {}\\n\\n\\n# Evaluate the model if training was successful\\nif model_trained and dataset and len(dataset.get('X_test', [])) > 0:\\n    print(\\\"ğŸ“Š Evaluating model on test set...\\\")\\n    \\n    evaluation_results = evaluate_model_performance(\\n        safety_model, \\n        dataset['X_test'], \\n        dataset['y_test']\\n    )\\n    \\n    if evaluation_results:\\n        print(\\\"\\\\nğŸ“ˆ Test Set Performance:\\\")\\n        print(f\\\"Accuracy: {evaluation_results['accuracy']:.3f}\\\")\\n        print(f\\\"Precision: {evaluation_results['precision']:.3f}\\\")\\n        print(f\\\"Recall: {evaluation_results['recall']:.3f}\\\")\\n        print(f\\\"F1-Score: {evaluation_results['f1_score']:.3f}\\\")\\n        \\n        if evaluation_results['roc_auc'] is not None:\\n            print(f\\\"ROC AUC: {evaluation_results['roc_auc']:.3f}\\\")\\n            \\n        print(\\\"\\\\nğŸ“Š Confusion Matrix:\\\")\\n        cm = evaluation_results['confusion_matrix']\\n        print(f\\\"True Negatives (Unsafe correctly predicted): {cm[0,0]}\\\")\\n        print(f\\\"False Positives (Unsafe predicted as Safe): {cm[0,1]}\\\")\\n        print(f\\\"False Negatives (Safe predicted as Unsafe): {cm[1,0]}\\\")\\n        print(f\\\"True Positives (Safe correctly predicted): {cm[1,1]}\\\")\\n        \\n        # Calculate safety-specific metrics\\n        total_predictions = len(evaluation_results['true_labels'])\\n        safe_sites_identified = np.sum(evaluation_results['predictions'])\\n        actual_safe_sites = np.sum(evaluation_results['true_labels'])\\n        \\n        print(f\\\"\\\\nğŸ›¡ï¸ Safety Assessment Summary:\\\")\\n        print(f\\\"Total test sites: {total_predictions}\\\")\\n        print(f\\\"Sites predicted as safe: {safe_sites_identified}\\\")\\n        print(f\\\"Actually safe sites: {actual_safe_sites}\\\")\\n        print(f\\\"False positive rate (unsafe sites marked safe): {cm[0,1]/(cm[0,0]+cm[0,1]):.3f}\\\")\\n        print(f\\\"False negative rate (safe sites marked unsafe): {cm[1,0]/(cm[1,0]+cm[1,1]):.3f}\\\")\\n        \\n        print(\\\"\\\\nâœ… Model evaluation completed!\\\")\\n        \\nelse:\\n    evaluation_results = {}\\n    print(\\\"âŒ Cannot evaluate model - no test data available or model not trained\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d7a06",
   "metadata": {},
   "source": [
    "## 9. ğŸ§ª Test Landing Safety Assessment\n",
    "\n",
    "Now let's test our trained model on sample images and demonstrate the complete assessment pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the complete assessment pipeline\n",
    "if model_trained and dataset and len(dataset.get('paths_test', [])) > 0:\n",
    "    print(\"ğŸ§ª Testing landing safety assessment pipeline...\")\n",
    "    \n",
    "    # Select a few test images for demonstration\n",
    "    test_images = dataset['paths_test'][:5]  # Test first 5 images\n",
    "    \n",
    "    print(f\"\\nğŸ” Assessing {len(test_images)} test landing sites...\")\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for i, image_path in enumerate(test_images):\n",
    "        print(f\"\\n--- Assessment {i+1}/5 ---\")\n",
    "        print(f\"ğŸ“¸ Image: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # Perform safety assessment\n",
    "        assessment = assess_landing_safety(image_path, safety_model)\n",
    "        \n",
    "        if assessment['status'] == 'success':\n",
    "            print(f\"ğŸ›¡ï¸ Safety Status: {assessment['safety_status'].upper()}\")\n",
    "            print(f\"ğŸ“Š Confidence: {assessment['confidence']:.3f}\")\n",
    "            print(f\"ğŸ’­ Recommendation: {assessment['recommendation']}\")\n",
    "            \n",
    "            # Show key features\n",
    "            features = assessment['features']\n",
    "            print(f\"\\nğŸ“‹ Key Features:\")\n",
    "            print(f\"  â€¢ Max Slope: {features.get('max_slope', 0):.1f}\")\n",
    "            print(f\"  â€¢ Surface Roughness: {features.get('glcm_contrast', 0):.3f}\")\n",
    "            print(f\"  â€¢ Edge Density: {features.get('edge_density', 0):.3f}\")\n",
    "            print(f\"  â€¢ Texture Std: {features.get('std_intensity', 0):.1f}\")\n",
    "            \n",
    "            # Show risk factors\n",
    "            risk_factors = assessment['risk_factors']\n",
    "            print(f\"\\nâš ï¸ Risk Factors:\")\n",
    "            for risk_type, risk_level in risk_factors.items():\n",
    "                emoji = \"ğŸ”´\" if risk_level == 'high' else \"ğŸŸ¡\" if risk_level == 'medium' else \"ğŸŸ¢\"\n",
    "                print(f\"  {emoji} {risk_type.title()}: {risk_level}\")\n",
    "                \n",
    "            test_results.append(assessment)\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Assessment failed: {assessment.get('message', 'Unknown error')}\")\n",
    "    \n",
    "    # Summary of test results\n",
    "    if test_results:\n",
    "        safe_count = sum(1 for r in test_results if r['safety_status'] == 'safe')\n",
    "        unsafe_count = len(test_results) - safe_count\n",
    "        avg_confidence = np.mean([r['confidence'] for r in test_results])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Test Assessment Summary:\")\n",
    "        print(f\"Total sites assessed: {len(test_results)}\")\n",
    "        print(f\"Safe landing sites: {safe_count}\")\n",
    "        print(f\"Unsafe landing sites: {unsafe_count}\")\n",
    "        print(f\"Average confidence: {avg_confidence:.3f}\")\n",
    "        \n",
    "        # Compare with actual labels if available\n",
    "        actual_labels = dataset['y_test'][:len(test_results)]\n",
    "        predicted_labels = [1 if r['safety_status'] == 'safe' else 0 for r in test_results]\n",
    "        \n",
    "        if len(actual_labels) == len(predicted_labels):\n",
    "            correct_predictions = sum(1 for actual, pred in zip(actual_labels, predicted_labels) if actual == pred)\n",
    "            accuracy = correct_predictions / len(actual_labels)\n",
    "            print(f\"Test accuracy on these samples: {accuracy:.3f}\")\n",
    "            \n",
    "        print(\"\\nâœ… Testing pipeline completed successfully!\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot test pipeline - model not trained or no test data available\")\n",
    "    test_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e4b2c",
   "metadata": {},
   "source": [
    "## 10. ğŸ“Š Visualize Results and Analysis\n",
    "\n",
    "Finally, let's create comprehensive visualizations of our results and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390df084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "if model_trained and evaluation_results:\n",
    "    print(\"ğŸ“Š Creating comprehensive visualizations...\")\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 1. Confusion Matrix Heatmap\n",
    "    plt.subplot(2, 3, 1)\n",
    "    cm = evaluation_results['confusion_matrix']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Unsafe', 'Safe'], \n",
    "                yticklabels=['Unsafe', 'Safe'])\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 2. Feature Importance Bar Plot\n",
    "    plt.subplot(2, 3, 2)\n",
    "    feature_importance = safety_model.get_feature_importance()\n",
    "    if feature_importance:\n",
    "        features = list(feature_importance.keys())[:10]  # Top 10 features\n",
    "        importance_values = list(feature_importance.values())[:10]\n",
    "        \n",
    "        bars = plt.barh(range(len(features)), importance_values)\n",
    "        plt.yticks(range(len(features)), features)\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Top 10 Feature Importance', fontsize=14, fontweight='bold')\n",
    "        plt.gca().invert_yaxis()\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.3f}', ha='left', va='center')\n",
    "    \n",
    "    # 3. Model Performance Metrics\n",
    "    plt.subplot(2, 3, 3)\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    values = [\n",
    "        evaluation_results['accuracy'],\n",
    "        evaluation_results['precision'],\n",
    "        evaluation_results['recall'],\n",
    "        evaluation_results['f1_score']\n",
    "    ]\n",
    "    \n",
    "    bars = plt.bar(metrics, values, color=['skyblue', 'lightgreen', 'orange', 'pink'])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. ROC Curve (if available)\n",
    "    if evaluation_results.get('roc_auc') is not None:\n",
    "        plt.subplot(2, 3, 4)\n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve(evaluation_results['true_labels'], \n",
    "                                  evaluation_results['probabilities'])\n",
    "            plt.plot(fpr, tpr, 'b-', linewidth=2, \n",
    "                    label=f'ROC Curve (AUC = {evaluation_results[\"roc_auc\"]:.3f})')\n",
    "            plt.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random Classifier')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        except:\n",
    "            plt.text(0.5, 0.5, 'ROC Curve\\nNot Available', \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. Prediction Confidence Distribution\n",
    "    plt.subplot(2, 3, 5)\n",
    "    probabilities = evaluation_results['probabilities']\n",
    "    plt.hist(probabilities, bins=20, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Class Distribution\n",
    "    plt.subplot(2, 3, 6)\n",
    "    true_labels = evaluation_results['true_labels']\n",
    "    predicted_labels = evaluation_results['predictions']\n",
    "    \n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    \n",
    "    true_counts = [np.sum(true_labels == 0), np.sum(true_labels == 1)]\n",
    "    pred_counts = [np.sum(predicted_labels == 0), np.sum(predicted_labels == 1)]\n",
    "    \n",
    "    plt.bar(x - width/2, true_counts, width, label='True Labels', alpha=0.8)\n",
    "    plt.bar(x + width/2, pred_counts, width, label='Predictions', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, ['Unsafe', 'Safe'])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Model performance visualizations created!\")\n",
    "    \n",
    "    # Additional Analysis Summary\n",
    "    print(f\"\\nğŸ“ˆ Final Model Analysis Summary:\")\n",
    "    print(f\"â•\" * 50)\n",
    "    print(f\"ğŸ¤– Model Type: Random Forest Classifier\")\n",
    "    print(f\"ğŸ“Š Training Samples: {training_metrics.get('n_samples', 'N/A')}\")\n",
    "    print(f\"ğŸ“ Feature Dimensions: {training_metrics.get('n_features', 'N/A')}\")\n",
    "    print(f\"\\nğŸ¯ Cross-Validation Performance:\")\n",
    "    print(f\"   Accuracy: {training_metrics.get('cv_accuracy_mean', 0):.3f} Â± {training_metrics.get('cv_accuracy_std', 0):.3f}\")\n",
    "    print(f\"   Precision: {training_metrics.get('cv_precision_mean', 0):.3f} Â± {training_metrics.get('cv_precision_std', 0):.3f}\")\n",
    "    print(f\"   Recall: {training_metrics.get('cv_recall_mean', 0):.3f} Â± {training_metrics.get('cv_recall_std', 0):.3f}\")\n",
    "    print(f\"   F1-Score: {training_metrics.get('cv_f1_mean', 0):.3f} Â± {training_metrics.get('cv_f1_std', 0):.3f}\")\n",
    "    print(f\"\\nğŸ§ª Test Set Performance:\")\n",
    "    print(f\"   Accuracy: {evaluation_results['accuracy']:.3f}\")\n",
    "    print(f\"   Precision: {evaluation_results['precision']:.3f}\")\n",
    "    print(f\"   Recall: {evaluation_results['recall']:.3f}\")\n",
    "    print(f\"   F1-Score: {evaluation_results['f1_score']:.3f}\")\n",
    "    \n",
    "    if evaluation_results.get('roc_auc'):\n",
    "        print(f\"   ROC AUC: {evaluation_results['roc_auc']:.3f}\")\n",
    "    \n",
    "    # Safety-critical metrics\n",
    "    cm = evaluation_results['confusion_matrix']\n",
    "    false_positive_rate = cm[0,1] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0\n",
    "    false_negative_rate = cm[1,0] / (cm[1,0] + cm[1,1]) if (cm[1,0] + cm[1,1]) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nâš ï¸ Safety-Critical Metrics:\")\n",
    "    print(f\"   False Positive Rate (unsafe â†’ safe): {false_positive_rate:.3f}\")\n",
    "    print(f\"   False Negative Rate (safe â†’ unsafe): {false_negative_rate:.3f}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nğŸ’¡ Recommendations:\")\n",
    "    if false_positive_rate > 0.1:\n",
    "        print(f\"   âš ï¸ High false positive rate - consider more conservative thresholds\")\n",
    "    if evaluation_results['accuracy'] > 0.8:\n",
    "        print(f\"   âœ… Good overall accuracy - model is performing well\")\n",
    "    if evaluation_results['recall'] < 0.7:\n",
    "        print(f\"   âš ï¸ Low recall - model may miss some safe landing sites\")\n",
    "    if evaluation_results['precision'] < 0.7:\n",
    "        print(f\"   âš ï¸ Low precision - model may incorrectly mark unsafe sites as safe\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot create visualizations - model not trained or evaluation not completed\")\n",
    "\n",
    "print(\"\\nğŸ‰ Mars Landing Safety Assessment Notebook Complete!\")\n",
    "print(\"ğŸš€ You now have a complete pipeline for assessing Mars landing site safety!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
