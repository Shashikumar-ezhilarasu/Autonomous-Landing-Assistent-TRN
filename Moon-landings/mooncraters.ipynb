{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vision'...\n",
      "remote: Enumerating objects: 590866, done.\u001b[K\n",
      "remote: Counting objects: 100% (1239/1239), done.\u001b[K\n",
      "remote: Compressing objects: 100% (932/932), done.\u001b[K\n",
      "Receiving objects: 100% (590866/590866), 1.12 GiB | 4.53 MiB/s, done.\n",
      "remote: Total 590866 (delta 1000), reused 351 (delta 301), pack-reused 589627 (from 5)\u001b[K\n",
      "Resolving deltas: 100% (552022/552022), done.\n",
      "error: pathspec 'v0.8.2' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": [
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "!git clone https://github.com/pytorch/vision.git\n",
    "!cd vision\n",
    "!git checkout v0.8.2\n",
    "\n",
    "!cp ./vision/references/detection/utils.py ./\n",
    "!cp ./vision/references/detection/transforms.py ./\n",
    "!cp ./vision/references/detection/coco_eval.py ./\n",
    "!cp ./vision/references/detection/engine.py ./\n",
    "!cp ./vision/references/detection/coco_utils.py ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Obtaining dependency information for cython from https://files.pythonhosted.org/packages/43/39/bdbec9142bc46605b54d674bf158a78b191c2b75be527c6dcf3e6dfe90b8/Cython-3.0.11-py2.py3-none-any.whl.metadata\n",
      "  Downloading Cython-3.0.11-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading Cython-3.0.11-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cython-3.0.11\n",
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /private/var/folders/n5/g9jzs83d0w34fq419d2bzwdh0000gn/T/pip-req-build-w7iffqka\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /private/var/folders/n5/g9jzs83d0w34fq419d2bzwdh0000gn/T/pip-req-build-w7iffqka\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pycocotools==2.0) (68.0.0)\n",
      "Requirement already satisfied: cython>=0.27.3 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pycocotools==2.0) (3.0.11)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pycocotools==2.0) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp311-cp311-macosx_11_0_arm64.whl size=81595 sha256=3350a1897e76675bc050952fc5b2e7a0a5286629e98e0efc4f3aacdb515b9191\n",
      "  Stored in directory: /private/var/folders/n5/g9jzs83d0w34fq419d2bzwdh0000gn/T/pip-ephem-wheel-cache-_bj1f53t/wheels/6d/69/75/358c50a37672dfda8d74ba3b30ec49fb75d52f7c081886d503\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0\n",
      "Requirement already satisfied: albumentations in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (1.4.14)\n",
      "Collecting albumentations\n",
      "  Obtaining dependency information for albumentations from https://files.pythonhosted.org/packages/af/ae/904b7bf58281d2bc1f3d6d48813bbcee742d1f8e3f9c0e1c451b0f67eb5a/albumentations-1.4.24-py3-none-any.whl.metadata\n",
      "  Downloading albumentations-1.4.24-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (1.14.1)\n",
      "Requirement already satisfied: PyYAML in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (6.0)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Obtaining dependency information for pydantic>=2.9.2 from https://files.pythonhosted.org/packages/f3/26/3e1bbe954fde7ee22a6e7d31582c642aad9e84ffe4b5fb61e63b87cd326f/pydantic-2.10.4-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting albucore==0.0.23 (from albumentations)\n",
      "  Obtaining dependency information for albucore==0.0.23 from https://files.pythonhosted.org/packages/3d/de/4d9298befa6ae0f21230378f55100dca364816e3734028ca2766f2eca263/albucore-0.0.23-py3-none-any.whl.metadata\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (4.10.0.84)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
      "  Obtaining dependency information for stringzilla>=3.10.4 from https://files.pythonhosted.org/packages/f2/f1/30ed72dd4251c269cc30122d257c9cbe26908133dc1976988ae56a4c76de/stringzilla-3.11.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading stringzilla-3.11.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m397.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
      "  Obtaining dependency information for simsimd>=5.9.2 from https://files.pythonhosted.org/packages/5d/2b/9e7d42ac54bdb32d76953db3bc83eec29bd5d5c9a4069d380b18e200d6bd/simsimd-6.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading simsimd-6.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m291.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Obtaining dependency information for pydantic-core==2.27.2 from https://files.pythonhosted.org/packages/9e/e3/71fe85af2021f3f386da42d291412e5baf6ce7716bd7101ea49c810eda90/pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Downloading albumentations-1.4.24-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m329.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.8/431.8 kB\u001b[0m \u001b[31m349.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m387.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading simsimd-6.2.1-cp311-cp311-macosx_11_0_arm64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m446.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-3.11.3-cp311-cp311-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m438.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: stringzilla, simsimd, pydantic-core, pydantic, albucore, albumentations\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.2\n",
      "    Uninstalling pydantic_core-2.23.2:\n",
      "      Successfully uninstalled pydantic_core-2.23.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.0\n",
      "    Uninstalling pydantic-2.9.0:\n",
      "      Successfully uninstalled pydantic-2.9.0\n",
      "  Attempting uninstall: albucore\n",
      "    Found existing installation: albucore 0.0.14\n",
      "    Uninstalling albucore-0.0.14:\n",
      "      Successfully uninstalled albucore-0.0.14\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 1.4.14\n",
      "    Uninstalling albumentations-1.4.14:\n",
      "      Successfully uninstalled albumentations-1.4.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.10.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed albucore-0.0.23 albumentations-1.4.24 pydantic-2.10.4 pydantic-core-2.27.2 simsimd-6.2.1 stringzilla-3.11.3\n",
      "Requirement already satisfied: opencv-python in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "cp: directory ./train/images does not exist\n",
      "cp: directory ./train/images does not exist\n",
      "cp: directory ./train/labels does not exist\n",
      "cp: directory ./train/labels does not exist\n"
     ]
    }
   ],
   "source": [
    "!pip install cython\n",
    "# Install pycocotools, the version by default in Colab\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "!pip install -U albumentations\n",
    "!pip install -U opencv-python\n",
    "\n",
    "#Copy and unify the train and validation datasets into one folder for images and another for labels\n",
    "!mkdir ./train\n",
    "!cp -a /kaggle/input/martianlunar-crater-detection-dataset/craters/train/images/. ./train/images/\n",
    "!cp -a /kaggle/input/martianlunar-crater-detection-dataset/craters/valid/images/. ./train/images/\n",
    "!cp -a /kaggle/input/martianlunar-crater-detection-dataset/craters/train/labels/. ./train/labels/\n",
    "!cp -a /kaggle/input/martianlunar-crater-detection-dataset/craters/valid/labels/. ./train/labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import time\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from  sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset class setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraterDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(self.root, \"images\"))))\n",
    "        self.annots = list(sorted(os.listdir(os.path.join(self.root, \"labels\"))))\n",
    "        self.classes = ['Background','Crater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Converts boundry box formats, this version assumes single class only!\n",
    "    def convert_box_cord(self,bboxs, format_from, format_to, img_shape):\n",
    "        if format_from == 'normxywh':\n",
    "            if format_to == 'xyminmax':\n",
    "                xw = bboxs[:, (1, 3)] * img_shape[1]\n",
    "                yh = bboxs[:, (2, 4)] * img_shape[0]\n",
    "                xmin = xw[:, 0] - xw[:, 1] / 2\n",
    "                xmax = xw[:, 0] + xw[:, 1] / 2\n",
    "                ymin = yh[:, 0] - yh[:, 1] / 2\n",
    "                ymax = yh[:, 0] + yh[:, 1] / 2\n",
    "                coords_converted = np.column_stack((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        return coords_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getitem__(self, idx):\n",
    "        # load images and boxes\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        annot_path = os.path.join(self.root, \"labels\", self.annots[idx])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img= img/255.0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1281466335.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if os.path.getsize(annot_path) != 0:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "       # retrieve bbox list and format to required type,\n",
    "        # if annotation file is empty, fill dummy box with label 0\n",
    "        if os.path.getsize(annot_path) != 0:\n",
    "            bboxs = np.loadtxt(annot_path, ndmin=2)\n",
    "            bboxs = self.convert_box_cord(bboxs, 'normxywh', 'xyminmax', img.shape)\n",
    "            num_objs = len(bboxs)\n",
    "            bboxs = torch.as_tensor(bboxs, dtype=torch.float32)\n",
    "            # there is only one class\n",
    "            labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "            # suppose all instances are not crowd\n",
    "            iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        else:\n",
    "            bboxs = torch.as_tensor([[0, 0, 640, 640]], dtype=torch.float32)\n",
    "            labels = torch.zeros((1,), dtype=torch.int64)\n",
    "            iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "\n",
    "        area = (bboxs[:, 3] - bboxs[:, 1]) * (bboxs[:, 2] - bboxs[:, 0])\n",
    "        image_id = torch.tensor([idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraterDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(self.root, \"images\"))))\n",
    "        self.annots = list(sorted(os.listdir(os.path.join(self.root, \"labels\"))))\n",
    "        self.classes = ['Background','Crater']\n",
    "        \n",
    "    # Converts boundry box formats, this version assumes single class only!\n",
    "    def convert_box_cord(self,bboxs, format_from, format_to, img_shape):\n",
    "        if format_from == 'normxywh':\n",
    "            if format_to == 'xyminmax':\n",
    "                xw = bboxs[:, (1, 3)] * img_shape[1]\n",
    "                yh = bboxs[:, (2, 4)] * img_shape[0]\n",
    "                xmin = xw[:, 0] - xw[:, 1] / 2\n",
    "                xmax = xw[:, 0] + xw[:, 1] / 2\n",
    "                ymin = yh[:, 0] - yh[:, 1] / 2\n",
    "                ymax = yh[:, 0] + yh[:, 1] / 2\n",
    "                coords_converted = np.column_stack((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        return coords_converted\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and boxes\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        annot_path = os.path.join(self.root, \"labels\", self.annots[idx])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img= img/255.0\n",
    "\n",
    "        # retrieve bbox list and format to required type,\n",
    "        # if annotation file is empty, fill dummy box with label 0\n",
    "        if os.path.getsize(annot_path) != 0:\n",
    "            bboxs = np.loadtxt(annot_path, ndmin=2)\n",
    "            bboxs = self.convert_box_cord(bboxs, 'normxywh', 'xyminmax', img.shape)\n",
    "            num_objs = len(bboxs)\n",
    "            bboxs = torch.as_tensor(bboxs, dtype=torch.float32)\n",
    "            # there is only one class\n",
    "            labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "            # suppose all instances are not crowd\n",
    "            iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        else:\n",
    "            bboxs = torch.as_tensor([[0, 0, 640, 640]], dtype=torch.float32)\n",
    "            labels = torch.zeros((1,), dtype=torch.int64)\n",
    "            iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "\n",
    "        area = (bboxs[:, 3] - bboxs[:, 1]) * (bboxs[:, 2] - bboxs[:, 0])\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = bboxs\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(image=img,\n",
    "                                     bboxes=target['boxes'],\n",
    "                                     labels=labels)\n",
    "        img = sample['image']\n",
    "        target['boxes'] = torch.tensor(sample['bboxes'])\n",
    "        target['labels'] = torch.tensor(sample['labels'])\n",
    "        if target['boxes'].ndim == 1:\n",
    "            target['boxes'] = torch.as_tensor([[0, 0, 640, 640]], dtype=torch.float32)\n",
    "            target['labels'] = torch.zeros((1,), dtype=torch.int64)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_bbox(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # A.Flip(p=0.5),\n",
    "            # A.RandomResizedCrop(height=640,width=640,p=0.4),\n",
    "            # # A.Perspective(p=0.4),\n",
    "            # A.Rotate(p=0.5),\n",
    "            # # A.Transpose(p=0.3),\n",
    "            ToTensorV2(p=1.0)],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc',min_visibility=0.4, label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2(p=1.0)],\n",
    "                         bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5, label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image visualization**\n",
    "The following function displays an image recieved from the dataset and overlays the boundry boxes from the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize bounding boxes in the image\n",
    "def plot_img_bbox(img, target):\n",
    "    # plot the image and bboxes\n",
    "    # Bounding boxes are defined as follows: x-min y-min width height\n",
    "    fig, a = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(5, 5)\n",
    "    a.imshow(img.permute((1,2,0)))\n",
    "    for box in (target['boxes']):\n",
    "        x, y, width, height = box[0], box[1], box[2] - box[0], box[3] - box[1]\n",
    "        rect = patches.Rectangle((x, y),\n",
    "                                 width, height,\n",
    "                                 edgecolor='b',\n",
    "                                 facecolor='none',\n",
    "                                 clip_on=False)\n",
    "        a.annotate('Crater', (x,y-20), color='blue', weight='bold',\n",
    "                   fontsize=10, ha='left', va='top')\n",
    "\n",
    "        # Draw the bounding box on top of the image\n",
    "        a.add_patch(rect)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images\u001b[39m\u001b[38;5;124m'\u001b[39m, get_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Prints an example of image with annotations\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mget_transform\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_transform\u001b[39m(train):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;66;03m# A.Flip(p=0.5),\u001b[39;00m\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;66;03m# A.RandomResizedCrop(height=640,width=640,p=0.4),\u001b[39;00m\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;66;03m# # A.Perspective(p=0.4),\u001b[39;00m\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;66;03m# A.Rotate(p=0.5),\u001b[39;00m\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;66;03m# # A.Transpose(p=0.3),\u001b[39;00m\n\u001b[1;32m      9\u001b[0m             ToTensorV2(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)],\n\u001b[1;32m     10\u001b[0m             bbox_params\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mBboxParams(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpascal_voc\u001b[39m\u001b[38;5;124m'\u001b[39m,min_visibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, label_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39mCompose([ToTensorV2(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)],\n\u001b[1;32m     13\u001b[0m                          bbox_params\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mBboxParams(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpascal_voc\u001b[39m\u001b[38;5;124m'\u001b[39m, min_visibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, label_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images', get_transform(train=True))\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (1.4.24)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (1.14.1)\n",
      "Requirement already satisfied: PyYAML in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (2.10.4)\n",
      "Requirement already satisfied: albucore==0.0.23 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albucore==0.0.23->albumentations) (3.11.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashikumarezhil/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:250: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39mCompose([ToTensorV2(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)],\n\u001b[1;32m     16\u001b[0m                          bbox_params\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mBboxParams(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpascal_voc\u001b[39m\u001b[38;5;124m'\u001b[39m, min_visibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, label_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images\u001b[39m\u001b[38;5;124m'\u001b[39m, get_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Prints an example of image with annotations\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mCraterDataset.__init__\u001b[0;34m(self, root, transforms)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# load all image files, sorting them to\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ensure that they are aligned\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m))))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m))))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackground\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrater\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # A.Flip(p=0.5),\n",
    "            # A.RandomResizedCrop(height=640,width=640,p=0.4),\n",
    "            # A.Perspective(p=0.4),\n",
    "            # A.Rotate(p=0.5),\n",
    "            # A.Transpose(p=0.3),\n",
    "            ToTensorV2(p=1.0)],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.4, label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2(p=1.0)],\n",
    "                         bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5, label_fields=['labels']))\n",
    "\n",
    "# Example usage\n",
    "dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images', get_transform(train=True))\n",
    "\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['011_png.rf.8ac312b4898f0106d10b76952a55d237.jpg', '020_png.rf.ce87f4889d7441275135633392f98ed7.jpg', 'mars_crater--103-_jpg.rf.61597458910fb0eed55b415c9cbac3bf.jpg', 'mars_crater--27-_jpg.rf.158fc0c6a694bba2f0afa44fd76a7f5a.jpg', 'mars_crater--20-_jpg.rf.cb4c2603f4a62bbe96328c29cec6d68e.jpg', 'mars_crater--111-_jpg.rf.215f88d6bd7a6d86560754be694fc2f3.jpg', 'mars_crater--86-_jpg.rf.81699898067809e7560109fb72a56670.jpg', 'mars_crater--74-_jpg.rf.259a2b0955c98b2b468d63917ae13796.jpg', 'mars_crater--15-_jpg.rf.c669035a909b835be84fa4fc67bf3f40.jpg', 'mars_crater--62-_jpg.rf.18dd7779b62fb78d5f07060fec32079d.jpg', 'mars_crater--4-_jpg.rf.b31f215c27d917bdb7c7c545db2bc36b.jpg', 'mars_crater--88-_jpg.rf.2f3b851dec48a94bfccc6519b4a45859.jpg', '01_png.rf.4d2ebc5ed98ad1e69d667aadbce63d53.jpg', 'mars_crater--8-_jpg.rf.85af0fa193ad2d5b0087dc48ec7341c6.jpg', 'mars_crater--93-_jpg.rf.7426ac666cec74a8b0bc15d550b8699b.jpg', '022_png.rf.00ae4e655a2774bada1e254641482935.jpg', 'mars_crater--53-_jpg.rf.20acc76fad4fecd456d4b0e77c9bbbb1.jpg', 'mars_crater--106-_jpg.rf.05aa3dbbbdc9651cb8c51d26c2847805.jpg', 'mars_crater--9-_jpg.rf.64378015a647ef92689e24ea103644cd.jpg', 'mars_crater--17-_jpg.rf.c051d4c804f2fed2aa32999cc9fd0b48.jpg', 'mars_crater--59-_jpg.rf.4f609e19d4f7f9987f696183edd87e99.jpg', 'mars_crater--35-_jpg.rf.826bc4b2a3a69c48144834f40d92439f.jpg', 'mars_crater--101-_jpg.rf.8f4eb1c77ab9e64d2fd691a6e0fcd3ec.jpg', '017_png.rf.1504c0d3ecbf20af6bc5114ca197a0dd.jpg', 'mars_crater--22-_jpg.rf.3ed23daa3923c22a459593cb449a7336.jpg', 'mars_crater--56-_jpg.rf.6f0dcbff4ea66014aef178b840d29238.jpg', 'mars_crater--10-_jpg.rf.585b1aa305997e3055e86fcac72a806b.jpg', 'mars_crater--36-_jpg.rf.0100a780ad4217b29c2dc9b46deec040.jpg', 'mars_crater--118-_jpg.rf.0a8b3fb0e1332e576901e596ad55e30a.jpg', 'mars_crater--24-_jpg.rf.4614bb6844fda70ea8a3b4f515cb7e8f.jpg', 'mars_crater--43-_jpg.rf.27ea7a65603205e491bc439c1d654cf4.jpg', 'mars_crater--49-_jpg.rf.5ea4703986c80bcfa03f0f99e4067c6f.jpg', 'mars_crater--110-_jpg.rf.593f6a3d9aed98e7a08955e700765222.jpg', 'mars_crater--37-_jpg.rf.c2a35d9de333416eb4d6d8f0d6b3310a.jpg', '06_png.rf.aaf8c66b9e4d5e99a3dc70bae7f62c07.jpg', 'mars_crater--85-_jpg.rf.344998b46a84deb2b8802cdae98c5282.jpg', 'mars_crater--52-_jpg.rf.1a227f21c518775052f847053022cd86.jpg', '016_png.rf.1973f9540ae7f672257609a8e5721ab3.jpg', 'mars_crater--2-_jpg.rf.a65bb7ee68968509ac0b28df75e1f251.jpg', 'mars_crater--83-_jpg.rf.3a468d2f7715d1cf73d5a31d385e0c34.jpg', 'mars_crater--26-_jpg.rf.e34074ddcd6c44fa17b7a7689f7ddfa4.jpg', 'mars_crater--82-_jpg.rf.c3ba3759df63259b6ba3df175475d3ce.jpg', 'mars_crater--54-_jpg.rf.2313c9f439999313bfb527534bbdc501.jpg', 'mars_crater--58-_jpg.rf.d668b2f63bd183cb629754db3ff6cf1f.jpg', '07_png.rf.3fba5e95c6827aa6c4132e70f2086555.jpg', '03_png.rf.8f7b31e14642026833b7c0dcd1832862.jpg', 'mars_crater--105-_jpg.rf.338dccc756e50430460dfb6f6191d1c5.jpg', 'mars_crater--99-_jpg.rf.09682f4dbe2f52ffe890061454306153.jpg', 'mars_crater--39-_jpg.rf.dbcaca888781a42f7bb3ce2c922da228.jpg', 'mars_crater--68-_jpg.rf.e503921bd751aed3cfd662cda03ab6b6.jpg', '018_png.rf.2d4eed5581681fe83830e51634befdaf.jpg', 'mars_crater--30-_jpg.rf.0fb68bf5aece1859bc5f080e66b4fef1.jpg', 'mars_crater--113-_jpg.rf.a7713d55de03a1a7487429d414e1005c.jpg', 'mars_crater--19-_jpg.rf.a9e7485a270816a553c3d7e0c3fddd30.jpg', 'mars_crater--50-_jpg.rf.02be16d199897982df8e6ea8f3e5818f.jpg', 'mars_crater--120-_jpg.rf.a870131b0b5974e8351a32ade2d5f0f3.jpg', 'mars_crater--81-_jpg.rf.147703ba93a36a6a753992752f0a1789.jpg', '09_png.rf.3b796e77a5f0036af4cd4413fcbe07a5.jpg', 'mars_crater--76-_jpg.rf.050c14a337ce70de3519fe6049640831.jpg', 'mars_crater--11-_jpg.rf.9e8de286e3d84938f34bb6bf35825343.jpg', 'mars_crater--41-_jpg.rf.5b367c681ccf0dfa9c5fddf287926d83.jpg', 'mars_crater--94-_jpg.rf.a1d59711147871b0498b03c2042c7b56.jpg', 'mars_crater--61-_jpg.rf.1398b749af6c18cf177cc97396129bd0.jpg', '012_png.rf.64da6ff4c62638096ee6e5bf689706bc.jpg', 'mars_crater--71-_jpg.rf.3370d6bdc02cbe6643f7509228f2ee10.jpg', 'mars_crater--7-_jpg.rf.84b2a78c125aa0230712626eb381a2b4.jpg', 'mars_crater--45-_jpg.rf.d69fa5e159ad8e5fe17b96deaba99c18.jpg', 'mars_crater--96-_jpg.rf.6dca8e5264f81785f8d718f92f9e4475.jpg', 'mars_crater--38-_jpg.rf.e6f3636efb075ba61dafa478e6b21de2.jpg', 'mars_crater--77-_jpg.rf.64732a16676a6c3222f67571cf1d6618.jpg', 'mars_crater--3-_jpg.rf.17bb27df5c5e6a501f790342675bc145.jpg', 'mars_crater--87-_jpg.rf.649d603d5617ce66e4a9420539fbfebb.jpg', 'mars_crater--84-_jpg.rf.dcfe6c285ac885441a1c95d818b188e1.jpg', 'mars_crater--6-_jpg.rf.ebff635e74e807f0377c656009482d1c.jpg', 'mars_crater--42-_jpg.rf.0cea1f9d9cf45fb141abf4e9aaae4c84.jpg', 'mars_crater--78-_jpg.rf.d960fe84ae55c6b91be086d8e8a8ed32.jpg', '02_png.rf.610687947e4c92f77e6462104ec4b924.jpg', '05_png.rf.844343145246e51e66a345419e1862bf.jpg', 'mars_crater--69-_jpg.rf.8677e1c58b60bd19c197032d3e749cda.jpg', 'mars_crater--18-_jpg.rf.8214037c811619bbe37024a557c9251f.jpg', 'mars_crater--57-_jpg.rf.a783aaeaf00ae5d57bec64438050285f.jpg', 'mars_crater--0-_jpg.rf.40c1dec94c66ab07d9da8c74fa58d6f8.jpg', 'mars_crater--80-_jpg.rf.55cff0d5b6e2587b15ba97e5f6a3a5f5.jpg', 'mars_crater--75-_jpg.rf.210df1cf8ebc1b962b63621720ecf926.jpg', '013_png.rf.ee44d5aa33fd33a1ed62ae233180f505.jpg', 'mars_crater--119-_jpg.rf.5cd500a3dcc977038a875b5115f9eda4.jpg', 'mars_crater--34-_jpg.rf.5617051b3d6a801330f8d4f7df9e3239.jpg', 'mars_crater--55-_jpg.rf.452ea46e23156b2c86433eb9054b1a6a.jpg', 'mars_crater--109-_jpg.rf.29afc1137114a2b872f484326254e949.jpg', 'mars_crater--14-_jpg.rf.e050bff73578e2a9ad30e339b898f839.jpg', 'mars_crater--5-_jpg.rf.6acb650edc64d6e1a02a0eef00e95113.jpg', 'mars_crater--16-_jpg.rf.bf5f6796b4ec5d351b47efae2e866934.jpg', 'mars_crater--44-_jpg.rf.627a604f51a4479d1f1660c5cf2af5c4.jpg', 'mars_crater--70-_jpg.rf.30c918cda3fcb18a9ff9ce047e0a93a0.jpg', 'mars_crater--21-_jpg.rf.63688e718106a9b061bb702a298e7a54.jpg', '08_png.rf.944efdd0f108140b368d7ad2c37426df.jpg', 'mars_crater--48-_jpg.rf.cc5528a8dcf4a11085a0a01d5c9084bc.jpg', 'mars_crater--102-_jpg.rf.9cdbcc724e2e7baf5c5c17aed91c769b.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images'\n",
    "files = os.listdir(path)\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images', get_transform(train=True))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Prints an example of image with annotations\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[1;32m     26\u001b[0m     plot_img_bbox(img, target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # A.Flip(p=0.5),\n",
    "            # A.RandomResizedCrop(height=640,width=640,p=0.4),\n",
    "            # A.Perspective(p=0.4),\n",
    "            # A.Rotate(p=0.5),\n",
    "            # A.Transpose(p=0.3),\n",
    "            ToTensorV2(p=1.0)],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.4, label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2(p=1.0)],\n",
    "                         bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5, label_fields=['labels']))\n",
    "\n",
    "# Example usage\n",
    "# dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images', get_transform(train=True))\n",
    "\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39mCompose([ToTensorV2(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)],\n\u001b[1;32m     18\u001b[0m                          bbox_params\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mBboxParams(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpascal_voc\u001b[39m\u001b[38;5;124m'\u001b[39m, min_visibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, label_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Define or initialize your dataset variable\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images\u001b[39m\u001b[38;5;124m'\u001b[39m, get_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Prints an example of image with annotations\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mCraterDataset.__init__\u001b[0;34m(self, root, transforms)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# load all image files, sorting them to\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ensure that they are aligned\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m))))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m))))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackground\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrater\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images/images'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define your transformation function\n",
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # A.Flip(p=0.5),\n",
    "            # A.RandomResizedCrop(height=640,width=640,p=0.4),\n",
    "            # A.Perspective(p=0.4),\n",
    "            # A.Rotate(p=0.5),\n",
    "            # A.Transpose(p=0.3),\n",
    "            ToTensorV2(p=1.0)],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.4, label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2(p=1.0)],\n",
    "                         bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5, label_fields=['labels']))\n",
    "\n",
    "# Define or initialize your dataset variable\n",
    "dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/trainimport random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define your transformation function\n",
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # A.Flip(p=0.5),\n",
    "            # A.RandomResizedCrop(height=640,width=640,p=0.4),\n",
    "            # A.Perspective(p=0.4),\n",
    "            # A.Rotate(p=0.5),\n",
    "            # A.Transpose(p=0.3),\n",
    "            ToTensorV2(p=1.0)],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.4, label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2(p=1.0)],\n",
    "                         bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5, label_fields=['labels']))\n",
    "\n",
    "# Define or initialize your dataset variable\n",
    "dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train/images', get_transform(train=True))\n",
    "\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)\n",
    "', get_transform(train=True))\n",
    "\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mget_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check if the dataset is correctly loading images\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m img, target \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Access the first image\u001b[39;00m\n\u001b[1;32m     27\u001b[0m img\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mCraterDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply transformations if any\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 18\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m=\u001b[39mimg)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, target\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:438\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m need_to_run:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m    441\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:449\u001b[0m, in \u001b[0;36mCompose.preprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess input data before applying transforms.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(data)\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_processors(data)\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_arrays(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:463\u001b[0m, in \u001b[0;36mCompose._validate_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in available keys.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_check_args:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:638\u001b[0m, in \u001b[0;36mCompose._check_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_name \u001b[38;5;129;01min\u001b[39;00m CHECKED_SINGLE:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be numpy array type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    639\u001b[0m     shapes\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class CraterDataset:\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.imgs = sorted(os.listdir(os.path.join(self.root, \"images\")))  # Listing image files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        img_path = os.path.join(self.root, \"images\", img_name)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        target = {}  # Add annotations or any other necessary information\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "# Example usage\n",
    "dataset = CraterDataset('/Users/shashikumarezhil/Documents/Autonomous-Lander/Moon-landings/craters/train', transform=get_transform(train=True))\n",
    "\n",
    "# Check if the dataset is correctly loading images\n",
    "img, target = dataset[0]  # Access the first image\n",
    "img.show()  # Display the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mCraterDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply transformations if any\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 18\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m=\u001b[39mimg)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, target\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:438\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m need_to_run:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m    441\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:449\u001b[0m, in \u001b[0;36mCompose.preprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess input data before applying transforms.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(data)\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_processors(data)\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_arrays(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:463\u001b[0m, in \u001b[0;36mCompose._validate_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in available keys.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_check_args:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/albumentations/core/composition.py:638\u001b[0m, in \u001b[0;36mCompose._check_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_name \u001b[38;5;129;01min\u001b[39;00m CHECKED_SINGLE:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be numpy array type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    639\u001b[0m     shapes\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "print(dataset[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Moon-landings/craters/train/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Moon-landings/craters/train\u001b[39m\u001b[38;5;124m'\u001b[39m, get_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Prints an example of image with annotations\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mCraterDataset.__init__\u001b[0;34m(self, root, transform)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m root\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Moon-landings/craters/train/images'"
     ]
    }
   ],
   "source": [
    "dataset = CraterDataset('/Moon-landings/craters/train', get_transform(train=True))\n",
    "# Prints an example of image with annotations\n",
    "for i in random.sample(range(1, 100), 3):\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'your_dataset_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myour_dataset_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CraterDataset, plot_img_bbox  \u001b[38;5;66;03m# Make sure to import necessary modules\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CraterDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Moon-landings/craters/train\u001b[39m\u001b[38;5;124m'\u001b[39m, get_transform(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'your_dataset_module'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from Moo import CraterDataset, plot_img_bbox  # Make sure to import necessary modules\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CraterDataset('/Moon-landings/craters/train', get_transform(train=True))\n",
    "\n",
    "# Prints examples of images with annotations\n",
    "for i in random.sample(range(1, len(dataset)), 3):  # Ensure you are sampling within the dataset size\n",
    "    img, target = dataset[i]\n",
    "    plot_img_bbox(img, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
